"""Standard loss functions that can be used inside of TransformLoss to
compute the loss between the generated guesses and the original
values.

License:
    MIT License

    Copyright (c) 2022 HUAWEI CLOUD

"""
# c2far/ml/loss_functions/standard_losses.py

TOLERANCE = 1e-6


class NDNormalizer():
    """Simply compute the average of the originals, for the purposes of
    globally normalizing the MAE to give us ND.

    """
    @staticmethod
    def __call__(_, originals):
        return originals.mean()


class CoverageLoss():
    """Loss function that computes how often the originals are within the
    low/high bounds returned by a multi-step-ahead generation
    evaluator.

    """
    @staticmethod
    def __call__(generated, originals):
        lows, highs = generated
        low_cov = lows <= originals + TOLERANCE
        high_cov = originals <= highs + TOLERANCE
        # -- note we use tolerance here because sometimes our
        # lows==highs, and floating-point equality is tough.
        cov = low_cov & high_cov
        nelem = len(cov)
        cov_loss = 1 - (cov.sum() / nelem)
        return cov_loss


class CovWidthLoss():
    """Loss function that computes the average width between the low/high
    bounds returned by a multi-step-ahead generation evaluator.

    """
    @staticmethod
    def __call__(generated, _):
        """Pass in generated and originals as all loss functions, but this one
        is only a function of the generated.

        """
        lows, highs = generated
        cov_width = (highs - lows).mean()
        return cov_width


class WQLLoss():
    """Loss function that computes 2*pinball loss of the orginals versus
    every predicted quantile from 0.1 to 0.9 (in the data generated by
    a multi-step-ahead generation evaluator).  Returns the average.

    """
    @staticmethod
    def __call__(generated, originals):
        """Get the average quantile loss (2*pinball_loss), across all levels,
        on all the examples.

        """
        taus = [x / 10.0 for x in range(1, 10)]
        y = originals  # for brevity
        tot_plosses = 0
        for u, tau in zip(generated, taus):
            # Casting boolean to float for indicator function (simpler
            # way of doing this with tensors):
            plosses = (y - u) * (tau - 1.0*(y < u))
            tot_plosses += plosses.mean()
        # Put the 2.0 back in, and take average over all taus:
        ploss = 2.0 * tot_plosses / 9
        # Now, you would divide this by the ND_NORMALIZER to get the
        # overall wQL, which is an approx to the CRPS.
        return ploss
